# Wikipedia Web Scraping

This folder contains Jupyter notebooks demonstrating web scraping techniques used to extract structured data from Wikipedia.

## Project Overview
The project focuses on scraping data from Wikipedia pages using Python libraries such as **Requests** and **BeautifulSoup**, and converting the extracted information into structured datasets for analysis.

## Dataset
- Source: Wikipedia  
- Example: *List of largest companies in the United States by revenue*
- Output: A cleaned CSV file containing company rank, name, industry, revenue, growth, employees, and headquarters.

## Tools & Libraries
- Python
- Requests
- BeautifulSoup (bs4)
- pandas

## Files
- **Wikipedia Web Scraping part 1.ipynb** – Web page request and HTML parsing  
- **Wikipedia Web Scraping part 2.ipynb** – Data extraction, cleaning, and CSV creation

## Learning Outcomes
- Sending HTTP requests to web pages
- Parsing HTML content
- Extracting table data from websites
- Structuring scraped data using pandas

